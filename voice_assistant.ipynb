{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#dotenv loads environment variables from a .env file at the root of your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import whisper\n",
    "import openai, subprocess\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY') \n",
    "\n",
    "from gtts import gTTS\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation uses whisper on the device\n",
    "# If you have trouble running on device, consider switching to using the openAI api for whisper speech to text\n",
    "model = whisper.load_model(\"small\")\n",
    "def speech_to_text(audio):\n",
    "    audio = whisper.load_audio(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    _, probs = model.detect_language(mel)\n",
    "    \n",
    "    options = whisper.DecodingOptions(fp16 = False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "                I want you to act as a comedian.\n",
    "                Your comedy is inspired by Chris Rock, Dave Chappelle, Jerry Seinfeld, and Louis C.K.\n",
    "                Your joke structure is more like Dr. Seuss.\n",
    "                You dont tell any jokes over 50 words.\n",
    "                \"\"\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "def chat_with_gpt(user_input_text):\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input_text})\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "\n",
    "    system_message = response[\"choices\"][0][\"message\"]\n",
    "    messages.append(system_message)\n",
    "    agent_response = system_message[\"content\"]\n",
    "    return agent_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio():\n",
    "    command = f\"play agent_response.mp3\"\n",
    "    subprocess.run(command,shell=True,stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"en\"\n",
    "def text_to_audio(agent_response):\n",
    "    gtts_object = gTTS(text = agent_response, \n",
    "                       lang = language,\n",
    "                       slow = False)\n",
    "    gtts_object.save(\"agent_response.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text_output():\n",
    "    chat_transcript = \"\"\n",
    "    for message in messages:\n",
    "        if message['role'] != 'system':\n",
    "            chat_transcript += message['role'] + \": \" + message['content'] + \"\\n\\n\"\n",
    "    return chat_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "dMhWUqKdNzn3",
    "outputId": "0ccdda3b-bd12-4836-d4af-ba8e8cace36c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(audio):\n",
    "    user_input = speech_to_text(audio)\n",
    "    agent_response = chat_with_gpt(user_input)\n",
    "    text_to_audio(agent_response)\n",
    "    play_audio()\n",
    "\n",
    "    chat_transcript = format_text_output()\n",
    "    return chat_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_input = gr.Audio(source=\"microphone\", type=\"filepath\")\n",
    "demo = gr.Interface(\n",
    "    fn=inference, \n",
    "    inputs=audio_input,\n",
    "    outputs=\"text\",\n",
    "    live=True\n",
    ")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "voice-assistant",
   "language": "python",
   "name": "voice-assistant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
